{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Classificador de contas contábeis\n",
    "O objetivo deste projeto é criar um classificador de contas contábeis para ajudar a identificar e categorizar lançamentos financeiros de uma empresa. Nessa primeira etapa, vamos explorar e analisar os dados para entender melhor o problema e identificar as características relevantes para o classificador.\n",
    "\n",
    "## Quais serão os próximos passos?\n",
    "- Aumentar a probabilidade de acerto para acima de 70%\n",
    "- Preencher a conta contábil quando estiver vazia e a probabilidade for maior de 70%. Caso contrário, dê uma sugestão da conta a ser preenchida na coluna \"Probabilidade\".\n",
    "- Criar um relatório de classificação com a matriz de confusão\n",
    "- Preencher a conta contábil e a probabilidade, gerando uma nova planilha com os resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Bibliotecas utilizadas\n",
    "- Pandas: carregamento, manipulação e tratamento de dados, transformando-os em DataFrame\n",
    "- Numpy: computação numérica\n",
    "- Scikit-learn: para o desenvolvimento do projeto (treinamento e avaliação do modelo)\n",
    "- Nltk: ferramenta para processamento de texto (stopwords)\n",
    "- Matplotlib e Seaborn: visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Bibliotecas para manipulação e análise de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "\n",
    "# - Bibliotecas para visualização de dados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# - Bibliotecas para ML\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# - Configurações de visualização\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## DataFrame com os dados\n",
    "A planilha a ser utilizada será **teste_contabeis_2024.xlsx**. Ela possui 5 colunas\n",
    "\n",
    " Colunas         | Valores                                      |\n",
    "|--------------------|-------------------------------------------------------|\n",
    "| CONTA             | Número da conta contábil                        |\n",
    "| BANCO  | Banco vinculado ao lançamento/conta contábil            |\n",
    "| DATA            | Data do lançamento           |\n",
    "| DESCRIÇÃO DO LANÇAMENTO | Descrição do lançamento. Ex: Pagto. Salário  |  \n",
    "| VALOR | Valor do lançamento|\n",
    "\n",
    "Antes de iniciarmos as análises e testes de modelo, vamos verificar nosso *dataset*, analisando as 5 primeiras entradas e as dimensões do mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o DataFrame\n",
    "df = pd.read_excel('teste_contabeis_2024.xlsx')\n",
    "\n",
    "# Exibindo as primeiras linhas do DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando a dimensão do DataFrame\n",
    "print(f\"O DataFrame possui {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "print(\"--------------------------------\")\n",
    "# Informações técnicas do DataFrame\n",
    "df.info()\n",
    "print(\"--------------------------------\")\n",
    "# pegando colunas e colocando em dataset\n",
    "dataset = df.columns.tolist()\n",
    "print(dataset)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "# Verificando contas contábeis a serem classificadas\n",
    "num_classes = df['CONTA'].nunique()\n",
    "print(f\"Número de contas contábeis únicas: {num_classes}\")\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Como as contas estão distribuídas?\n",
    "Criando um *DataFrame* para mostrar a distribuição de lançamentos por conta contábil. Logo em seguida, plotarei esses dados para melhor visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montagem de grafico de barras para visualizar a distribuição das classes\n",
    "print(\"Distribuição de lançamentos por conta contábil: \")\n",
    "count_contas = df['CONTA'].value_counts()\n",
    "print(count_contas)\n",
    "print(\"--------------------------------\")\n",
    "# Plotando o gráfico de barras\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x=count_contas.index, y=count_contas.values, palette=\"viridis\")\n",
    "plt.title(\"Distribuição de Lançamentos por Conta Contábil\")\n",
    "plt.xlabel(\"Conta Contábil\")\n",
    "plt.ylabel(\"Número de Lançamentos\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Como podemos tratar o texto para fazer a classificação?\n",
    "Para tratar o texto, vamos utilizar o *nltk* para limpar o texto com as *stopwords*.\n",
    "\n",
    "- **Stopwords**: são as palavras mais comuns e frequentes em um idioma ou contexto, que servem como conexão para formar uma oração ou frase. Elas podem ser removidas do texto para melhorar a qualidade da classificação.\n",
    "\n",
    "O *dataset* a seguir faz a comparação do histórico original com o histórico limpo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento de texto - descrição\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# função para limpar o texto\n",
    "def clean_text(text):\n",
    "    # transformar em minúsculas\n",
    "    text = str(text).lower()\n",
    "    # remover numeros\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    # remover pontuação e caracteres especiais\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # remover espaços extras\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remover stopwords\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "    # Opcional: adicionar stopwords condizentes ao contexto\n",
    "    custom_stopwords = {'Lançamento', 'pagto', 'aplicações'}\n",
    "    # update\n",
    "    stopwords_pt.update(custom_stopwords)\n",
    "    # Separar as palavras\n",
    "    words = text.split()\n",
    "    # Remover as stopwords\n",
    "    words_filtered = [word for word in words if word not in stopwords_pt and len(word) > 2]\n",
    "    # Juntar as palavras novamente\n",
    "    clean_text = ' '.join(words_filtered)\n",
    "    return clean_text\n",
    "\n",
    "print(\"Limpando os textos das descrições...\")\n",
    "# Aplicando a função de limpeza ao DataFrame\n",
    "# Criando uma coluna com o texto limpo\n",
    "df[\"DESCRIÇÃO_LIMPA\"] = df[\"DESCRIÇÃO DO LANÇAMENTO\"].apply(clean_text)\n",
    "# Comparação\n",
    "print(\"Comparação entre texto original e texto limpo:\")\n",
    "df[[\"DESCRIÇÃO DO LANÇAMENTO\", \"DESCRIÇÃO_LIMPA\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Quais são as palavras mais frequentes?\n",
    "O *dataset* a seguir mostra as palavras mais frequentes após o tratamento do histórico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de frequência das palavras\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "# matriz de contagem de palavras\n",
    "arr_count = count_vectorizer.fit_transform(df[\"DESCRIÇÃO_LIMPA\"])\n",
    "# Somando as ocorrências de cada palavra\n",
    "sum_words = arr_count.sum(axis=0)\n",
    "# Criando um dicionário de palavras e suas frequências\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in count_vectorizer.vocabulary_.items()]\n",
    "# Ordenar lista da mais frequente para a menos frequente\n",
    "words_freq_sorted = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "# Criando DataFrame\n",
    "df_words_freq = pd.DataFrame(words_freq_sorted, columns=['Palavra', 'Frequência'])\n",
    "\n",
    "# Mostrando as palavras mais frequentes\n",
    "print(\"Palavras mais frequentes nas descrições limpas:\")\n",
    "df_words_freq.head(50) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Criando o modelo\n",
    "Antes de criar o modelo, é criado um filtro para prepará-lo. A divisão do modelo deve ter estratificação com pelo menos 5 ocorrências por classe. A divisão entre dados é composta por: **70% treino e 30% teste**.\n",
    "Lembrando que:\n",
    "\n",
    "##### **X = coluna com histórico**\n",
    "##### **y = coluna com as contas contábeis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando filtro para preparar modelo. A divisão do modelo deve ter estratificação com pelo menos 5 ocorrências por classe\n",
    "count_acc = df['CONTA'].value_counts()\n",
    "valid_acc = count_acc[count_acc >= 5].index\n",
    "df_filtered = df[df['CONTA'].isin(valid_acc)]\n",
    "\n",
    "# Criando primeiro modelo de teste\n",
    "X = df_filtered[\"DESCRIÇÃO_LIMPA\"]\n",
    "y = df_filtered[\"CONTA\"]\n",
    "# Divisão entre dados de treino e teste: 70% treino e 30% teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "# Definir e criar pipeline\n",
    "text_clf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])   \n",
    "# Treinando o pipeline\n",
    "text_clf_pipeline.fit(X_train, y_train)\n",
    "print(\"Modelo treinado com sucesso!\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Relatorio de classificação\n",
    "O relatório nos mostrará o resultado da classificação dividido em 4 colunas:\n",
    "\n",
    "- **Precision**: de toda a classificação, qual a porcentagem de acertos? (Mede a qualidade da previsão)\n",
    "- **Recall**: de todos os exemplos que realmente eram de *X*, quantos o modelo conseguiu encontrar? (Mede a quantidade de acertos)\n",
    "- **F1-Score**: uma média entre *Precision* e *Recall*. Ótima métrica para verificar o balanceamento do *dataset*\n",
    "- **Accuracy**: Acurácia é a porcentagem de acertos em relação ao total de previsões\n",
    "(Acurácia = Número de acertos / Número total de amostras)\n",
    "\n",
    "## Matriz de confusão\n",
    "Para ter uma visão mais detalhada de onde tivemos acertos e erros, usaremos a Matriz de Confusão\n",
    "\n",
    "- Linhas representam a conta real\n",
    "- Colunas representam a conta prevista pelo modelo\n",
    "- Os números na diagonal principal são os acertos\n",
    "- Qualquer número fora da diagonal representa um erro de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo, criando matriz de confusão e relatório de classificação\n",
    "# Usando o pipeline para fazer previsões\n",
    "y_pred = text_clf_pipeline.predict(X_test)\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Gerar e visualizar matriz de confusão\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(y_test.unique())\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.ylabel('Conta Real')\n",
    "plt.xlabel('Conta Prevista')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Análise de keywords\n",
    "Aqui será analisado a distribuição das keywords, dividindo seus resultados em 3 colunas:\n",
    "\n",
    "- Keyword: são as palavras consideradas como principais na classificação do lançamento\n",
    "- Frequência total: quantas vezes elas aparecem\n",
    "- Conta dominante: nas vezes em que aparecem, em quais contas seus lançamentos costumam ser atribuídos\n",
    "  \n",
    "Através desses dados, é possível prever quais palavras são mais determinantes e menos ambíguas na hora de realizar a classificação dos lançamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a distribuição das keywords, verificando se pertencem a mais de uma conta\n",
    "from tqdm.auto import tqdm # barra de progresso\n",
    "print(\"Iniciando análise de palavras-chave...\")\n",
    "df_analysis = df_filtered.copy()\n",
    "# Extraindo todo o vocabulário\n",
    "vectorizer_vocab = CountVectorizer(min_df=2)\n",
    "vectorizer_vocab.fit(df_analysis[\"DESCRIÇÃO_LIMPA\"])\n",
    "vocab = vectorizer_vocab.get_feature_names_out()\n",
    "print(f\"Vocabulário extraído com {len(vocab)} palavras.\")\n",
    "\n",
    "# Iterar sobre cada palavra e calcular as estatísticas\n",
    "analysis_list = []\n",
    "for word in tqdm(vocab, desc=\"Analisando palavras\"):\n",
    "    # Filtrar linhas que contêm a palavra\n",
    "    df_word = df_analysis[df_analysis[\"DESCRIÇÃO_LIMPA\"].str.contains(rf'\\b{word}\\b', regex=True)]\n",
    "    if not df_word.empty:\n",
    "        total_freq = len(df_word)\n",
    "        dist = df_word['CONTA'].value_counts()\n",
    "        dominant_acc = dist.index[0]\n",
    "        dominant_freq = dist.iloc[0]\n",
    "        exclusivity = (dominant_freq / total_freq) * 100\n",
    "        \n",
    "        # Guarda os resultados\n",
    "        analysis_list.append({\n",
    "            \"Keyword\": word,\n",
    "            \"Frequência Total\": total_freq,\n",
    "            \"Conta dominante\": dominant_acc,\n",
    "            \"Frequência na conta dominante\": dominant_freq,\n",
    "            \"Exclusividade (%)\": exclusivity\n",
    "        })\n",
    "# Criando DataFrame com os resultados\n",
    "df_keyword_analysis = pd.DataFrame(analysis_list)\n",
    "# Ordenando por exclusividade\n",
    "df_keyword_analysis_sorted = df_keyword_analysis.sort_values(by=\"Exclusividade (%)\", ascending=True)\n",
    "\n",
    "# Mostrando as palavras com maior exclusividade\n",
    "print(\"Palavras com maior exclusividade:\")\n",
    "print(df_keyword_analysis_sorted.head(50))\n",
    "print(\"--------------------------------\")\n",
    "# Menos exclusivas\n",
    "print(\"Palavras com menor exclusividade:\")\n",
    "print(df_keyword_analysis_sorted[df_keyword_analysis_sorted[\"Frequência Total\"] > 10].sort_values(by=\"Exclusividade (%)\", ascending=False).head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Probabilidade de previsão\n",
    "Aqui será mostrado a probabilidade de previsão pela ordem das classes do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de previsão e coluna de classificação\n",
    "print(\"Calculando probabilidades de previsão\")\n",
    "# Obter a matriz de probabilidades\n",
    "arr_proba = text_clf_pipeline.predict_proba(X)\n",
    "# Ordem da classe conforme o modelo\n",
    "model_classes = text_clf_pipeline.classes_\n",
    "print(f\"Ordem das classes conforme o modelo: {model_classes}\")\n",
    "# Criação do map para encontrar o índice da classe\n",
    "class_index_map = {cls: i for i, cls in enumerate(model_classes)}\n",
    "# Para cada linha do dataset, descobrir qual o indice da classe\n",
    "# Pegando dados de y, que são as contas reais de cada lançamento\n",
    "index_real_cls = y.map(class_index_map).values\n",
    "# Calculando a probabilidade da classe real para cada linha\n",
    "real_proba = arr_proba[np.arange(len(y)), index_real_cls]\n",
    "# Criando coluna no DataFrame\n",
    "df_filtered.loc[:, 'CLASSIFICAÇÃO_PROB'] = real_proba * 100\n",
    "\n",
    "# Mostrando o resultado final\n",
    "print(\"\\nResultado final...\")\n",
    "df_display = df_filtered.copy()\n",
    "df_display['CLASSIFICAÇÃO_PROB'] = df_display['CLASSIFICAÇÃO_PROB'].map('{:.2f}%'.format)\n",
    "\n",
    "# Exibir colunas mais importantes\n",
    "columns_to_display = ['DESCRIÇÃO DO LANÇAMENTO', 'DESCRIÇÃO_LIMPA', 'CLASSIFICAÇÃO_PROB']\n",
    "print(df_display[columns_to_display].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Testando inserção de dados\n",
    "Testada uma nova entrada e retornando a probabilidade de previsão. Nota-se que a probabilidade de previsão vai diminuindo conforme o modelo aprende mais das contas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando com novo lançamento\n",
    "new_entries = [\"pagto alexandre dias\"]\n",
    "# Limpando os novos lançamentos\n",
    "new_entries_clean = clean_text(new_entries)\n",
    "# Fazendo previsões\n",
    "proba = text_clf_pipeline.predict_proba([new_entries_clean])\n",
    "# Obtendo classes previstas\n",
    "classes = text_clf_pipeline.classes_\n",
    "# DataFrame mostrando resultados. O .T deixa as contas como linhas\n",
    "df_results = pd.DataFrame(proba, columns=classes).T\n",
    "df_results.rename(columns={0: 'Probabilidade'}, inplace=True)\n",
    "# Convertendo para porcentagem\n",
    "df_results['Probabilidade'] = df_results['Probabilidade'] * 100\n",
    "# Ordenando da maior para a menor probabilidade\n",
    "df_results_sorted = df_results.sort_values(by='Probabilidade', ascending=False)\n",
    "df_results_sorted['Probabilidade'] = df_results_sorted['Probabilidade'].map('{:.2f}%'.format) \n",
    "print(\"Resultados das previsões para novos lançamentos:\")\n",
    "print(df_results_sorted)\n",
    "\n",
    "# Mostrando a melhor e pior previsão do modelo\n",
    "print(\"Analisando a melhor previsão do modelo...\")\n",
    "# Encontrando a melhor previsão\n",
    "best_acc = df_results_sorted.iloc[0]\n",
    "best_proba = df_results_sorted.iloc[0,0]\n",
    "print(f\"Melhor previsão: Conta {best_acc.name} com probabilidade de {best_proba}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando modelo treinado\n",
    "import joblib\n",
    "model_name = 'modelo_contabil_pipeline.joblib'\n",
    "joblib.dump(text_clf_pipeline, model_name)\n",
    "print(f\"Modelo salvo em {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Testando o modelo já salvo\n",
    "Repetindo os testes anteriores, mas agora usando o modelo salvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando modelo salvo\n",
    "load_model = joblib.load(model_name)\n",
    "test_entry = [\"TESTE. pagto alexandre dias\"]\n",
    "# Usando modelo carregado para fazer previsão\n",
    "predict = load_model.predict(test_entry)\n",
    "proba = load_model.predict_proba(test_entry)\n",
    "# Pega a probabilidade da classe prevista\n",
    "max_prob = proba.max()\n",
    "\n",
    "print(\"\\nTestando modelo salvo...\")\n",
    "print(f\"O lançamento '{test_entry[0]}' foi classificado na conta '{predict[0]}' com probabilidade de {max_prob*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
