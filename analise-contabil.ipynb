{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Bibliotecas para manipulação e análise de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "\n",
    "# - Bibliotecas para visualização de dados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# - Bibliotecas para ML\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# - Configurações de visualização\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o DataFrame\n",
    "df = pd.read_excel('lanc_cont_ml.xlsx')\n",
    "\n",
    "# Exibindo as primeiras linhas do DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando a dimensão do DataFrame\n",
    "print(f\"O DataFrame possui {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "print(\"--------------------------------\")\n",
    "# Informações técnicas do DataFrame\n",
    "df.info()\n",
    "print(\"--------------------------------\")\n",
    "# pegando colunas e colocando em dataset\n",
    "dataset = df.columns.tolist()\n",
    "print(dataset)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "# Verificando contas contábeis a serem classificadas\n",
    "num_classes = df['CONTA'].nunique()\n",
    "print(f\"Número de contas contábeis únicas: {num_classes}\")\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montagem de grafico de barras para visualizar a distribuição das classes\n",
    "print(\"Distribuição de lançamentos por conta contábil: \")\n",
    "count_contas = df['CONTA'].value_counts()\n",
    "print(count_contas)\n",
    "print(\"--------------------------------\")\n",
    "# Plotando o gráfico de barras\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x=count_contas.index, y=count_contas.values, palette=\"viridis\")\n",
    "plt.title(\"Distribuição de Lançamentos por Conta Contábil\")\n",
    "plt.xlabel(\"Conta Contábil\")\n",
    "plt.ylabel(\"Número de Lançamentos\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento de texto - descrição\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# função para limpar o texto\n",
    "def clean_text(text):\n",
    "    # transformar em minúsculas\n",
    "    text = str(text).lower()\n",
    "    # remover numeros\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    # remover pontuação e caracteres especiais\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # remover espaços extras\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remover stopwords\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "    # Opcional: adicionar stopwords condizentes ao contexto\n",
    "    custom_stopwords = {'Lançamento', 'teste'}\n",
    "    # update\n",
    "    stopwords_pt.update(custom_stopwords)\n",
    "    # Separar as palavras\n",
    "    words = text.split()\n",
    "    # Remover as stopwords\n",
    "    words_filtered = [word for word in words if word not in stopwords_pt and len(word) > 2]\n",
    "    # Juntar as palavras novamente\n",
    "    clean_text = ' '.join(words_filtered)\n",
    "    return clean_text\n",
    "\n",
    "print(\"Limpando os textos das descrições...\")\n",
    "# Aplicando a função de limpeza ao DataFrame\n",
    "# Criando uma coluna com o texto limpo\n",
    "df[\"DESCRIÇÃO_LIMPA\"] = df[\"DESCRIÇÃO DO LANÇAMENTO\"].apply(clean_text)\n",
    "# Comparação\n",
    "print(\"Comparação entre texto original e texto limpo:\")\n",
    "df[[\"DESCRIÇÃO DO LANÇAMENTO\", \"DESCRIÇÃO_LIMPA\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de frequência das palavras\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "# matriz de contagem de palavras\n",
    "arr_count = count_vectorizer.fit_transform(df[\"DESCRIÇÃO_LIMPA\"])\n",
    "# Somando as ocorrências de cada palavra\n",
    "sum_words = arr_count.sum(axis=0)\n",
    "# Criando um dicionário de palavras e suas frequências\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in count_vectorizer.vocabulary_.items()]\n",
    "# Ordenar lista da mais frequente para a menos frequente\n",
    "words_freq_sorted = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "# Criando DataFrame\n",
    "df_words_freq = pd.DataFrame(words_freq_sorted, columns=['Palavra', 'Frequência'])\n",
    "\n",
    "# Mostrando as palavras mais frequentes\n",
    "print(\"Palavras mais frequentes nas descrições limpas:\")\n",
    "df_words_freq.head(50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando primeiro modelo de teste\n",
    "X = df[\"DESCRIÇÃO_LIMPA\"]\n",
    "y = df[\"CONTA\"]\n",
    "# Divisão entre dados de treino e teste: 70% treino e 30% teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "# Definir e criar pipeline\n",
    "text_clf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])   \n",
    "# Treinando o pipeline\n",
    "text_clf_pipeline.fit(X_train, y_train)\n",
    "print(\"Modelo treinado com sucesso!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo, criando matriz de confusão e relatório de classificação\n",
    "# Usando o pipeline para fazer previsões\n",
    "y_pred = text_clf_pipeline.predict(X_test)\n",
    "# Imprimindo o relatório de classificação\n",
    "print(\"Relatório de Classificação: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Gerar e visualizar matriz de confusão\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(y_test.unique())\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.ylabel('Conta Real')\n",
    "plt.xlabel('Conta Prevista')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a distribuição das keywords, verificando se pertencem a mais de uma conta\n",
    "keyword_dict = {\n",
    "    \"salario\": \"20101\",\n",
    "    \"aluguel\": \"20102\",\n",
    "    \"google\": \"20103\",\n",
    "    \"imposto\": \"20104\",\n",
    "    \"fornecedor\": \"20105\",\n",
    "    \"software\": \"20106\",\n",
    "    \"viagem\": \"20107\",\n",
    "    \"cliente\": \"30101\",\n",
    "    \"venda\": \"30102\",\n",
    "    \"juros\": \"30103\",\n",
    "    }\n",
    "print(\"Análise das keywords nas contas contábeis: \")\n",
    "\n",
    "# Loop\n",
    "for keyword, estimated_account in keyword_dict.items():\n",
    "    df_contains_kw = df[df['DESCRIÇÃO_LIMPA'].str.contains(keyword, case=False, na=False)]\n",
    "    dist = df_contains_kw['CONTA'].value_counts()\n",
    "    # Analisando a distribuição\n",
    "    is_exclusive = len(dist) == 1 and str(dist.index[0]) == estimated_account\n",
    "    print(f\"Keyword: {keyword}\")\n",
    "    print(f\"Conta esperada: {estimated_account}\")\n",
    "    \n",
    "    if not dist.empty:\n",
    "        print(\"Distribuição das contas para essa keyword:\")\n",
    "        print(dist)\n",
    "        if is_exclusive:\n",
    "            print(f\"A keyword '{keyword}' é exclusiva para a conta {estimated_account}.\")\n",
    "        else:\n",
    "            print(f\"A keyword '{keyword}' não é exclusiva para a conta {estimated_account}.\")\n",
    "    else:\n",
    "        print(f\"Nenhum lançamento encontrado com a keyword '{keyword}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidade de previsão e coluna de classificação\n",
    "print(\"Calculando probabilidades de previsão\")\n",
    "# Obter a matriz de probabilidades\n",
    "arr_proba = text_clf_pipeline.predict_proba(X)\n",
    "# Ordem da classe conforme o modelo\n",
    "model_classes = text_clf_pipeline.classes_\n",
    "print(f\"Ordem das classes conforme o modelo: {model_classes}\")\n",
    "# Criação do map para encontrar o índice da classe\n",
    "class_index_map = {cls: i for i, cls in enumerate(model_classes)}\n",
    "# Para cada linha do dataset, descobrir qual o indice da classe\n",
    "# Pegando dados de y, que são as contas reais de cada lançamento\n",
    "index_real_cls = y.map(class_index_map).values\n",
    "# Calculando a probabilidade da classe real para cada linha\n",
    "real_proba = arr_proba[np.arange(len(y)), index_real_cls]\n",
    "# Criando coluna no DataFrame\n",
    "df['CLASSIFICAÇÃO_PROB'] = real_proba * 100\n",
    "\n",
    "# Mostrando o resultado final\n",
    "print(\"\\nResultado final...\")\n",
    "df_display = df.copy()\n",
    "df_display['CLASSIFICAÇÃO_PROB'] = df_display['CLASSIFICAÇÃO_PROB'].map('{:.2f}%'.format)\n",
    "\n",
    "# Exibir colunas mais importantes\n",
    "columns_to_display = ['DESCRIÇÃO DO LANÇAMENTO', 'DESCRIÇÃO_LIMPA', 'CLASSIFICAÇÃO_PROB']\n",
    "print(df_display[columns_to_display].head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
